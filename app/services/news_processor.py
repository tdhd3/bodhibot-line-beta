import requests
import logging
import random
from typing import Dict, List, Optional
from datetime import datetime
import xml.etree.ElementTree as ET
import re

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

from app.core.config import settings

# é…ç½®æ—¥èªŒ
logger = logging.getLogger(__name__)

class NewsProcessor:
    """æ–°èè™•ç†å™¨ï¼Œç”¨æ–¼ç²å–æœ€æ–°æ–°èä¸¦å¾ä½›æ•™è§’åº¦æä¾›è§€é»"""
    
    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ–æ–°èè™•ç†å™¨
        Args:
            api_key: GNews APIçš„APIå¯†é‘°
        """
        self.api_key = api_key or settings.GNEWS_API_KEY
        # GNews API
        self.news_api_url = "https://gnews.io/api/v4/top-headlines"
        # å°ç£ä¸­å¤®ç¤¾RSS
        self.cna_rss_url = "https://www.cna.com.tw/RSS/MainNews.aspx"
        
        # å‚™ç”¨æ–°èæº (å¦‚æœAPIä¸å¯ç”¨)
        self.fallback_urls = [
            "https://news.google.com/rss?hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
            "https://www.ettoday.net/rss/news-list.xml",
            "https://feeds.feedburner.com/pts_news"
        ]
        
    def _fetch_news(self) -> Optional[List[Dict]]:
        """
        å¾GNews APIç²å–æ–°è
        Returns:
            æ–°èå­—å…¸åˆ—è¡¨æˆ–None
        """
        if not self.api_key:
            logger.warning("æœªè¨­ç½®GNews APIå¯†é‘°ï¼Œä½¿ç”¨å‚™ç”¨æ–°èæº")
            return self._fetch_fallback_news()
            
        try:
            # æ·»åŠ ç©æ¥µæ­£é¢çš„é—œéµè©å’Œé¡åˆ¥
            positive_topics = ["åœ‹éš›é—œä¿‚", "ç¶“æ¿Ÿç™¼å±•", "æ”¿ç­–æ”¹é©", "ç§‘æŠ€å‰µæ–°", "æ–‡åŒ–äº¤æµ"]
            selected_topic = random.choice(positive_topics)
            
            params = {
                "token": self.api_key,
                "lang": "zh",
                "country": "tw",
                "max": 10,
                "q": selected_topic,  # æ·»åŠ æ­£é¢é—œéµè©
                "sortby": "relevance"  # æŒ‰ç›¸é—œæ€§æ’åº
            }
            
            response = requests.get(self.news_api_url, params=params)
            
            if response.status_code == 200:
                data = response.json()
                articles = data.get("articles", [])
                
                if articles:
                    # éæ¿¾æ–°èï¼Œç§»é™¤å¯èƒ½åŒ…å«è² é¢å…§å®¹çš„æ¨™é¡Œ
                    negative_keywords = ["æ­»äº¡", "æ®ºå®³", "äº‹æ•…", "ç½é›£", "å–ªç”Ÿ", "å¢œæ©Ÿ", "æ§æ“Š", "è‡ªæ®º", "å¤±è¹¤", "ç½ªçŠ¯"]
                    filtered_articles = [
                        article for article in articles 
                        if not any(keyword in article.get("title", "").lower() for keyword in negative_keywords)
                    ]
                    
                    # å¦‚æœéæ¿¾å¾Œä»æœ‰è¶³å¤ çš„æ–°è
                    if len(filtered_articles) >= 3:
                        # éš¨æ©Ÿé¸æ“‡ä¸‰æ¢ä¸åŒçš„æ–°è
                        selected_articles = random.sample(filtered_articles, 3)
                    elif filtered_articles:
                        selected_articles = filtered_articles
                    else:
                        # å¦‚æœéæ¿¾å¾Œæ²’æœ‰æ–°èï¼Œå˜—è©¦ä½¿ç”¨å‚™ç”¨æ–°èæº
                        return self._fetch_fallback_news()
                        
                    news_list = []
                    for article in selected_articles:
                        news_list.append({
                            "title": article.get("title", ""),
                            "description": article.get("description", ""),
                            "url": article.get("url", ""),
                            "source": article.get("source", {}).get("name", ""),
                            "category": selected_topic  # æ·»åŠ é¡åˆ¥ä¿¡æ¯
                        })
                    return news_list
            elif response.status_code == 401:
                logger.warning("GNews APIå¯†é‘°ç„¡æ•ˆæˆ–å·²éæœŸï¼Œä½¿ç”¨å‚™ç”¨æ–°èæº")
                return self._fetch_fallback_news()
            else:
                logger.warning(f"GNews APIè«‹æ±‚å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}ï¼Œä½¿ç”¨å‚™ç”¨æ–°èæº")
                return self._fetch_fallback_news()
            
        except Exception as e:
            logger.error(f"å¾GNews APIç²å–æ–°èæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}ï¼Œä½¿ç”¨å‚™ç”¨æ–°èæº")
            return self._fetch_fallback_news()
            
    def _fetch_fallback_news(self) -> Optional[List[Dict]]:
        """
        å¾å‚™ç”¨æºç²å–æ–°è
        Returns:
            æ–°èå­—å…¸åˆ—è¡¨æˆ–None
        """
        try:
            # å˜—è©¦ä½¿ç”¨ä¸­å¤®ç¤¾RSS
            response = requests.get(self.cna_rss_url, timeout=10)
            
            if response.status_code == 200:
                try:
                    # è§£æRSS
                    root = ET.fromstring(response.content)
                    items = root.findall(".//item")
                    
                    if items and len(items) >= 3:
                        # éæ¿¾è² é¢æ–°è
                        negative_keywords = ["æ­»äº¡", "æ®ºå®³", "äº‹æ•…", "ç½é›£", "å–ªç”Ÿ", "å¢œæ©Ÿ", "æ§æ“Š", "è‡ªæ®º", "å¤±è¹¤", "ç½ªçŠ¯"]
                        filtered_items = []
                        
                        # é¦–å…ˆæ‰¾å‡ºåœ‹éš›æ”¿æ²»ã€ç¶“æ¿Ÿç›¸é—œæ–°è
                        positive_categories = ["åœ‹éš›", "å…©å²¸", "æ”¿æ²»", "ç”¢ç¶“", "è­‰åˆ¸", "ç§‘æŠ€", "æ–‡åŒ–"]
                        
                        # å„ªå…ˆé¸æ“‡ç¬¦åˆé¡åˆ¥çš„æ–°è
                        for item in items:
                            title = item.find("title").text if item.find("title") is not None else ""
                            # æª¢æŸ¥æ˜¯å¦åŒ…å«æ­£é¢é¡åˆ¥
                            if any(category in title for category in positive_categories):
                                # ç¢ºä¿ä¸åŒ…å«è² é¢é—œéµè©
                                if not any(keyword in title.lower() for keyword in negative_keywords):
                                    filtered_items.append(item)
                        
                        # å¦‚æœç¬¦åˆé¡åˆ¥çš„æ–°èä¸è¶³3æ¢ï¼Œå†å¾å…¶ä»–æ–°èä¸­é¸æ“‡
                        if len(filtered_items) < 3:
                            for item in items:
                                title = item.find("title").text if item.find("title") is not None else ""
                                if item not in filtered_items and not any(keyword in title.lower() for keyword in negative_keywords):
                                    filtered_items.append(item)
                                if len(filtered_items) >= 3:
                                    break
                        
                        # å¦‚æœéæ¿¾å¾Œä»æœ‰è¶³å¤ çš„æ–°è
                        if filtered_items and len(filtered_items) >= 3:
                            # éš¨æ©Ÿé¸æ“‡ä¸‰æ¢æ–°è
                            selected_items = random.sample(filtered_items, 3)
                        elif filtered_items:
                            selected_items = filtered_items
                        else:
                            # å¦‚æœæ²’æœ‰ç¬¦åˆæ¢ä»¶çš„æ–°èï¼Œé¸æ“‡åŸå§‹é …ç›®
                            selected_items = random.sample(items, 3)
                        
                        news_list = []
                        for item in selected_items:
                            title = item.find("title").text if item.find("title") is not None else ""
                            description = item.find("description").text if item.find("description") is not None else ""
                            link = item.find("link").text if item.find("link") is not None else ""
                            
                            # æ¸…ç†æè¿°ä¸­çš„HTMLæ¨™ç±¤
                            description = re.sub(r'<[^>]+>', '', description)
                            
                            # ç¢ºå®šæ–°èé¡åˆ¥
                            category = "ä¸€èˆ¬æ–°è"
                            for cat in positive_categories:
                                if cat in title:
                                    category = cat
                                    break
                            
                            news_list.append({
                                "title": title,
                                "description": description,
                                "url": link,
                                "source": "ä¸­å¤®ç¤¾",
                                "category": category
                            })
                        return news_list
                except ET.ParseError:
                    logger.warning("è§£æä¸­å¤®ç¤¾RSSæ™‚å‡ºéŒ¯ï¼Œå˜—è©¦å…¶ä»–å‚™ç”¨æº")
                    
            # å¦‚æœä¸­å¤®ç¤¾ä¸å¯ç”¨ï¼Œå˜—è©¦å…¶ä»–å‚™ç”¨æº
            for url in self.fallback_urls:
                try:
                    response = requests.get(url, timeout=10)
                    
                    if response.status_code == 200:
                        # è§£æRSS
                        root = ET.fromstring(response.content)
                        items = root.findall(".//item")
                        
                        if items and len(items) >= 3:
                            # éæ¿¾è² é¢æ–°è
                            negative_keywords = ["æ­»äº¡", "æ®ºå®³", "äº‹æ•…", "ç½é›£", "å–ªç”Ÿ", "å¢œæ©Ÿ", "æ§æ“Š", "è‡ªæ®º", "å¤±è¹¤", "ç½ªçŠ¯"]
                            filtered_items = []
                            
                            # å„ªå…ˆé¸æ“‡åœ‹éš›æ”¿æ²»ã€ç¶“æ¿Ÿç›¸é—œæ–°è
                            positive_categories = ["åœ‹éš›", "å…©å²¸", "æ”¿æ²»", "ç”¢ç¶“", "è­‰åˆ¸", "ç§‘æŠ€", "æ–‡åŒ–"]
                            
                            for item in items:
                                title = item.find("title").text if item.find("title") is not None else ""
                                # æª¢æŸ¥æ˜¯å¦åŒ…å«æ­£é¢é¡åˆ¥
                                if any(category in title for category in positive_categories):
                                    # ç¢ºä¿ä¸åŒ…å«è² é¢é—œéµè©
                                    if not any(keyword in title.lower() for keyword in negative_keywords):
                                        filtered_items.append(item)
                            
                            # å¦‚æœç¬¦åˆé¡åˆ¥çš„æ–°èä¸è¶³3æ¢ï¼Œå†å¾å…¶ä»–æ–°èä¸­é¸æ“‡
                            if len(filtered_items) < 3:
                                for item in items:
                                    title = item.find("title").text if item.find("title") is not None else ""
                                    if item not in filtered_items and not any(keyword in title.lower() for keyword in negative_keywords):
                                        filtered_items.append(item)
                                    if len(filtered_items) >= 3:
                                        break
                            
                            # å¦‚æœéæ¿¾å¾Œä»æœ‰è¶³å¤ çš„æ–°è
                            if filtered_items and len(filtered_items) >= 3:
                                # éš¨æ©Ÿé¸æ“‡ä¸‰æ¢æ–°è
                                selected_items = random.sample(filtered_items, 3)
                            elif filtered_items:
                                selected_items = filtered_items
                            else:
                                # å¦‚æœæ²’æœ‰ç¬¦åˆæ¢ä»¶çš„æ–°èï¼Œé¸æ“‡åŸå§‹é …ç›®
                                selected_items = random.sample(items, 3)
                            
                            news_list = []
                            for item in selected_items:
                                title = item.find("title").text if item.find("title") is not None else ""
                                description = item.find("description").text if item.find("description") is not None else ""
                                link = item.find("link").text if item.find("link") is not None else ""
                                source = url.split("/")[2]
                                
                                # æ¸…ç†æè¿°ä¸­çš„HTMLæ¨™ç±¤
                                description = re.sub(r'<[^>]+>', '', description)
                                
                                # ç¢ºå®šæ–°èé¡åˆ¥
                                category = "ä¸€èˆ¬æ–°è"
                                for cat in positive_categories:
                                    if cat in title:
                                        category = cat
                                        break
                                
                                news_list.append({
                                    "title": title,
                                    "description": description,
                                    "url": link,
                                    "source": source,
                                    "category": category
                                })
                            return news_list
                except (ET.ParseError, requests.RequestException) as e:
                    logger.warning(f"å¾ {url} ç²å–æ–°èæ™‚å‡ºéŒ¯: {str(e)}")
                    continue
                        
            logger.error("æ‰€æœ‰æ–°èæºå˜—è©¦å¤±æ•—")
            return None
            
        except Exception as e:
            logger.error(f"å¾å‚™ç”¨æºç²å–æ–°èæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return None

    def _create_short_url(self, long_url: str) -> str:
        """
        ç”ŸæˆçŸ­ç¶²å€ï¼ˆç°¡å–®ç‰ˆï¼‰
        Args:
            long_url: é•·ç¶²å€
        Returns:
            çŸ­ç¶²å€æˆ–åŸå§‹ç¶²å€
        """
        try:
            # é€™è£¡å¯ä»¥é›†æˆå¯¦éš›çš„çŸ­ç¶²å€æœå‹™ï¼Œå¦‚TinyURLæˆ–Bitly
            # ç›®å‰åƒ…è¿”å›åŸå§‹URL
            return long_url
        except Exception as e:
            logger.error(f"ç”ŸæˆçŸ­ç¶²å€æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return long_url
            
    async def get_daily_news(self, llm: ChatOpenAI = None) -> List[Dict]:
        """
        ç²å–æ¯æ—¥æ–°èä¸¦æ·»åŠ è§€é»
        Args:
            llm: èªè¨€æ¨¡å‹ï¼ˆå¦‚æœæœªæä¾›ï¼Œå‰‡ä½¿ç”¨é…ç½®ä¸­çš„é»˜èªæ¨¡å‹ï¼‰
        Returns:
            åŒ…å«æ–°èæ¨™é¡Œã€å…§å®¹ã€é€£çµå’Œè§€é»çš„å­—å…¸åˆ—è¡¨
        """
        try:
            # å¦‚æœæœªæä¾›LLMï¼Œä½¿ç”¨é»˜èªè¨­ç½®å‰µå»ºä¸€å€‹
            if llm is None:
                llm = ChatOpenAI(
                    openai_api_key=settings.OPENAI_API_KEY,
                    model=settings.GPT_MODEL,
                    temperature=0.7
                )
            
            # å˜—è©¦ç²å–æ–°è
            news_list = self._fetch_news()
            if not news_list:
                # ä½¿ç”¨å‚™ç”¨æ–°è
                news_list = self._fetch_fallback_news()
                
            if not news_list:
                # å¦‚æœä»ç„¶æ²’æœ‰æ–°èï¼Œè¿”å›é è¨­æ¶ˆæ¯
                return [{
                    "title": "ç„¡æ³•ç²å–ä»Šæ—¥æ–°è",
                    "content": "ç•¶ä¸‹å³æ˜¯æœ€å¥½çš„æ–°è",
                    "url": "",
                    "perspective": "æˆ‘å€‘å¯ä»¥å°ˆæ³¨æ–¼ç•¶ä¸‹ï¼Œè§€å¯Ÿå‘¨åœç™¼ç”Ÿçš„äº‹æƒ…ï¼Œç†è§£ä¸–ç•Œçš„é‹ä½œæ–¹å¼ã€‚"
                }]
            
            # é‡å°æ¯æ¢æ–°èç”Ÿæˆè§€é»    
            result_news = []
            for news in news_list:
                # ä½¿ç”¨LLMç”Ÿæˆè§€é»
                perspective = await self._generate_buddhist_perspective(news, llm)
                
                result_news.append({
                    "title": news.get("title", "ä»Šæ—¥æ–°è"),
                    "content": news.get("description", ""),
                    "url": news.get("url", ""),
                    "source": news.get("source", ""),
                    "perspective": perspective
                })
                
            return result_news
            
        except Exception as e:
            logger.error(f"ç²å–æ–°èæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            # è¿”å›é è¨­æ¶ˆæ¯
            return [{
                "title": "æ¯æ—¥çœæ€",
                "content": "åæ€æˆ‘å€‘èˆ‡ä¸–ç•Œçš„é€£çµ",
                "url": "",
                "perspective": "åœ¨ç´›ç¹çš„ä¸–ç•Œä¸­ï¼Œæˆ‘å€‘å¯ä»¥å­¸ç¿’å¦‚ä½•ä¿æŒå¹³éœå’Œæ™ºæ…§ï¼Œé—œæ³¨æ­£å‘æ”¹è®Šã€‚"
            }]
            
    async def _generate_buddhist_perspective(self, news: Dict, llm: ChatOpenAI) -> str:
        """
        ç”Ÿæˆä½›æ•™è§€é»
        Args:
            news: æ–°èå­—å…¸
            llm: èªè¨€æ¨¡å‹
        Returns:
            è§€é»
        """
        try:
            title = news.get("title", "")
            content = news.get("description", "")
            category = news.get("category", "ä¸€èˆ¬æ–°è")
            
            prompt = f"""è§’è‰²è¨­å®šï¼š
ä½ æ˜¯ä¸€ä½æ™ºæ…§å°å¸«ï¼Œæ“…é•·å¾å®¢è§€è§’åº¦å¯©è¦–ç•¶å‰åœ‹éš›æƒ…å‹¢å’Œåœ‹å…§æ”¿ç¶“ç™¼å±•ï¼Œæä¾›ä¸­ç«‹è€Œå¯Œæœ‰å•Ÿç™¼æ€§çš„è§€é»ã€‚

[æ–°èæ¨™é¡Œ]: {title}
[æ–°èé¡åˆ¥]: {category}
[æ–°èå…§å®¹]: {content}

è«‹ç”Ÿæˆä¸€æ®µä¸è¶…é100å­—çš„å®¢è§€çœæ€ï¼Œè¦æ±‚ï¼š
1. ä¿æŒæ”¿æ²»ã€å®—æ•™ä¸­ç«‹ï¼Œä¸åå‘ä»»ä½•ç«‹å ´
2. è‘—é‡æ–¼ã€Œå› ç·£é—œè¯ã€å’Œã€Œç„¡å¸¸è®ŠåŒ–ã€ç­‰ä½›æ³•æ™ºæ…§åœ¨è©²æ–°èä¸­çš„é«”ç¾
3. æä¾›å•Ÿç™¼æ€§çš„è§€é»ï¼Œå¼•å°è®€è€…æ·±å…¥æ€è€ƒäº‹ä»¶èƒŒå¾Œçš„æœ¬è³ª
4. è‹¥æ˜¯ç¶“æ¿Ÿæˆ–æ”¿æ²»æ–°èï¼Œå¯å¾ã€Œä¸­é“ã€èˆ‡ã€Œå¹³è¡¡ã€çš„è§’åº¦é€²è¡Œè§£è®€
5. è‹¥æ˜¯åœ‹éš›é—œä¿‚æ–°èï¼Œå¯å¾ã€Œç›¸äº’ä¾å­˜ã€å’Œã€Œæ…ˆæ‚²åŒ…å®¹ã€çš„è§’åº¦åˆ†æ
6. é¿å…ä½¿ç”¨éå¤šä½›æ•™å°ˆæœ‰åè©ï¼Œä¿æŒé€šä¿—æ˜“æ‡‚

ç›´æ¥æä¾›å®¢è§€çœæ€å…§å®¹ï¼Œç„¡éœ€æ¨™é¡Œæˆ–é¡å¤–æ ¼å¼ã€‚"""

            response = await llm.ainvoke([HumanMessage(content=prompt)])
            return response.content
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆè§€é»æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            # è¿”å›é è¨­è§€é»
            return "é€™å‰‡æ–°èæé†’æˆ‘å€‘ï¼Œä¸–é–“è¬ç‰©ç›¸äº’é—œè¯ï¼Œæ¯ä¸€å€‹äº‹ä»¶éƒ½æ˜¯å› ç·£å’Œåˆçš„çµæœã€‚ä¿æŒé–‹æ”¾å®¢è§€çš„å¿ƒæ…‹å»ç†è§£äº‹ä»¶çš„å¤šé¢å‘ï¼Œä»¥æ™ºæ…§æ´å¯Ÿäº‹ç‰©çš„æœ¬è³ªï¼Œæ‰èƒ½åœ¨è¤‡é›œçš„ä¸–ç•Œä¸­æ‰¾åˆ°å¹³è¡¡èˆ‡ä¸­é“ã€‚"
            
    def format_daily_dharma(self, news_list: List[Dict]) -> str:
        """
        æ ¼å¼åŒ–æ¯æ—¥æ³•èª
        Args:
            news_list: æ–°èå­—å…¸åˆ—è¡¨
        Returns:
            æ ¼å¼åŒ–çš„æ¯æ—¥æ³•èª
        """
        formatted_text = f"ğŸ“° ä»Šæ—¥åœ‹éš›èˆ‡æ”¿ç¶“è§€å¯Ÿ - {datetime.now().strftime('%Y/%m/%d')}\n{'-'*20}\n\n"
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºåˆ—è¡¨
        if not isinstance(news_list, list):
            news_list = [news_list]
            
        # è™•ç†æ¯æ¢æ–°è
        for i, news in enumerate(news_list):
            title = news.get("title", "ä»Šæ—¥è§€å¯Ÿ")
            perspective = news.get("perspective", "")
            url = news.get("url", "")
            content = news.get("description", "")
            category = news.get("category", "ä¸€èˆ¬æ–°è")
            source = news.get("source", "")
            
            # ç¢ºä¿å…§å®¹ä¸æœƒå¤ªé•·
            if len(content) > 100:
                content = content[:97] + "..."
            
            # æ·»åŠ æ–°èæ¨™é¡Œå’Œé¡åˆ¥
            formatted_text += f"ã€{category}ã€‘{title}\n\n"
            
            # åˆ†æˆæ®µè½é¡¯ç¤ºå…§å®¹å’Œè§€é»
            formatted_text += f"ğŸ“Š è¦é»ï¼š{content}\n\n"
            
            formatted_text += f"ğŸ” å®¢è§€çœæ€ï¼š{perspective}\n\n"
            
            # æ·»åŠ æ€è€ƒå•é¡Œï¼Œæ ¹æ“šæ–°èé¡åˆ¥èª¿æ•´
            if "åœ‹éš›" in category or "å…©å²¸" in category:
                formatted_text += f"ğŸ’­ æ€è€ƒï¼šé€™äº›åœ‹éš›ç™¼å±•å¦‚ä½•é«”ç¾ã€Œç›¸äº’ä¾å­˜ã€çš„é“ç†ï¼Ÿ\n\n"
            elif "æ”¿æ²»" in category:
                formatted_text += f"ğŸ’­ æ€è€ƒï¼šå¦‚ä½•ä»¥ã€Œä¸­é“ã€çš„æ™ºæ…§ç†è§£é€™ä¸€æ”¿æ²»ç¾è±¡ï¼Ÿ\n\n"
            elif "ç¶“æ¿Ÿ" in category or "ç”¢ç¶“" in category or "è­‰åˆ¸" in category:
                formatted_text += f"ğŸ’­ æ€è€ƒï¼šç¶“æ¿Ÿè®ŠåŒ–ä¸­ï¼Œå¦‚ä½•ä¿æŒå¹³è¡¡å¿ƒæ…‹ï¼Ÿ\n\n"
            else:
                formatted_text += f"ğŸ’­ æ€è€ƒï¼šå¾å®¢è§€è§’åº¦ï¼Œæˆ‘å€‘èƒ½å¾ä¸­ç²å¾—ä»€éº¼å•Ÿç¤ºï¼Ÿ\n\n"
            
            if i < len(news_list) - 1:
                formatted_text += f"{'-'*20}\n\n"
        
        # æ·»åŠ ç°¡æ½”çš„åŸæ–‡å¼•ç”¨æ¨™é¡Œ
        if len(news_list) > 0:
            formatted_text += f"{'-'*20}\n"
            formatted_text += "ğŸ“‹ åŸå§‹ä¾†æº:\n"
            for i, news in enumerate(news_list):
                title = news.get("title", "")
                source = news.get("source", "")
                
                if title and source:
                    # åªé¡¯ç¤ºæ¨™é¡Œå’Œä¾†æºï¼Œä¸é¡¯ç¤ºURL
                    formatted_text += f"{i+1}. {source}: {title.split(' - ')[0]}\n"
                    
            formatted_text += "\n"
        
        # æ·»åŠ çµå°¾èª
        formatted_text += "ğŸŒ é¡˜ä»¥æ™ºæ…§ä¹‹çœ¼è§€ä¸–ç•Œï¼Œä»¥å¹³ç­‰ä¹‹å¿ƒå¾…è¬ç‰©"
            
        return formatted_text
    
    async def get_formatted_news(self) -> str:
        """
        ç²å–æ ¼å¼åŒ–çš„æ–°è
        Returns:
            æ ¼å¼åŒ–çš„æ–°èæ–‡æœ¬
        """
        try:
            news_list = await self.get_daily_news()
            return self.format_daily_dharma(news_list)
        except Exception as e:
            logger.error(f"ç²å–æ ¼å¼åŒ–æ–°èæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return "ç„¡æ³•ç²å–ä»Šæ—¥æ–°èï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

# å–®ä¾‹æ¨¡å¼å¯¦ä¾‹
news_processor = NewsProcessor() 